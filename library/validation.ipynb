{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "5ceedaab-335a-4e41-b7db-e393da407ca9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from datetime import date\n",
    "import sys,re\n",
    "from cryptography.fernet import Fernet\n",
    "import json\n",
    "import pandas as pd \n",
    "#typing_extensions\n",
    "\n",
    "import os,itertools\n",
    "from pathlib import Path\n",
    "import snowflake.connector\n",
    "from snowflake.snowpark.functions import *\n",
    "from snowflake.snowpark import *\n",
    "from snowflake.snowpark import DataFrame\n",
    "from snowflake.snowpark.session import *\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from geopy.geocoders import Nominatim\n",
    "from geopy.distance import geodesic\n",
    "import os\n",
    "import re\n",
    "#import helper as hp\n",
    "\n",
    "from datetime import datetime, timedelta\n",
    "from functools import reduce \n",
    "from snowflake.snowpark import Session\n",
    "from snowflake.snowpark.functions import substr,col, when,substr, substring, udf, upper, lit, split, trim, expr, replace, is_null, approx_count_distinct,regexp_replace, max as snow_max,concat,to_date,row_number,  array_slice,array_size,get,charindex,length,startswith,contains,cast, radians, sin, cos, sqrt, atan2,sum,round,count#,union\n",
    "from snowflake.snowpark.types import BooleanType, StringType, IntegerType, StructType, StructField, FloatType\n",
    "import psutil\n",
    "from snowflake.snowpark.exceptions import SnowparkSQLException\n",
    "from snowflake.snowpark.window import Window\n",
    "from snowflake.snowpark import functions as F\n",
    "import math\n",
    "import numpy as np\n",
    "\n",
    "%run \"./utility\"\n",
    "\n",
    "def compare_column_dtypes(df1, df2):\n",
    "    dtypes_df1 = df1.dtypes\n",
    "    dtypes_df2 = df2.dtypes\n",
    "    dtype_comparison = pd.DataFrame({\n",
    "        'Column': dtypes_df1.index,\n",
    "        'df1_dtype': dtypes_df1.values,\n",
    "        'df2_dtype': dtypes_df2.reindex(dtypes_df1.index).values\n",
    "    })\n",
    "    dtype_differences = dtype_comparison[dtype_comparison['df1_dtype'] != dtype_comparison['df2_dtype']]\n",
    "\n",
    "    return dtype_differences\n",
    "\n",
    "\n",
    "def convert_column_names_to_uppercase(df):\n",
    "    df.columns = [col.upper() for col in df.columns]\n",
    "    return df\n",
    "\n",
    "\n",
    "\n",
    "def float_comparator(x,y):\n",
    "    if np.isnan(x) and np.isnan(y):\n",
    "        return True\n",
    "    elif x ==y:\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "\n",
    " \n",
    "def comparator(x,y):\n",
    "    if type(x) ==float and type(y)==float:\n",
    "        return float_comparator(x,y)\n",
    "    elif x is None and y is None:\n",
    "        return True\n",
    "    elif x ==y:\n",
    "        return True\n",
    "    else:\n",
    "        return odd_compare(x,y)\n",
    "def odd_compare_float(x,y): \n",
    "    if type(x)==float and np.isnan(x):\n",
    "        if( str.strip(y)==''):\n",
    "           return True\n",
    "        else:\n",
    "            return False\n",
    "    else:\n",
    "        if( str.strip(x)==''):\n",
    "           return True\n",
    "        else:\n",
    "            return False     \n",
    "def odd_compare(x,y):\n",
    "    if type(x)==float or type(y)==float:\n",
    "        return odd_compare_float(x,y)\n",
    "    elif type(x)==str and type(y) ==str:\n",
    "        return (True if str.strip(x)==str.strip(y) else False)\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "\n",
    "# returns True is same else False\n",
    "def compare_dataframes(df1, df2, key_column, value_columns):\n",
    "    value_columns = [x for x in value_columns if x not in key_columns]\n",
    "    merged_df = df1.merge(df2, on=key_column, suffixes=('_df1', '_df2'))\n",
    "    merged_df_results = merged_df\n",
    "    #merged_df_keys = merged_df_results[key_columns]\n",
    "    #print(merged_df.columns)\n",
    "    #print('original count',df1.count,df2.count) #print(\"shapes of dfs\",df1.shape,df2.shape)\n",
    "    print(\"common records on given key\",merged_df.shape)\n",
    "    \n",
    "    discrepancies = pd.DataFrame()\n",
    "\n",
    "    for column in value_columns:\n",
    "        merged_df_results[f'{column}_df1df2'] = merged_df_results.apply(lambda row: 1 if comparator(row[f'{column}_df1'],row[f'{column}_df2']) else 0, axis=1)\n",
    "\n",
    "    return merged_df,merged_df_results#,merged_df_keys\n",
    "\n",
    "\n",
    "\n",
    "def get_columns_with_max_diff(df):\n",
    "    df_columns = df.columns\n",
    "    columns_df1df2 = []\n",
    "    for i in range(0,len(df_columns)):\n",
    "        if df_columns[i].endswith('_df1df2'):\n",
    "            columns_df1df2\n",
    "\n",
    "def count_zeros_in_columns(df):\n",
    "    # Identify columns ending with 'df1df2'\n",
    "    target_columns = [col for col in df.columns if col.endswith('df1df2')]\n",
    "    zero_counts = {}\n",
    "    for col in target_columns:\n",
    "        zero_counts[col] = (df[col] == 0).sum()\n",
    "    sorted_zero_counts = dict(sorted(zero_counts.items(), key=lambda item: item[1], reverse=True))\n",
    "    return zero_counts,sorted_zero_counts\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def df_dtype_compare(df1,df2):\n",
    "    dtypes_dict1 = df1.dtypes.apply(lambda x: x.name).to_dict()\n",
    "    dtypes_dict2 = df2.dtypes.apply(lambda x: x.name).to_dict()    \n",
    "    column_list1 = df1.columns\n",
    "    column_list2 = df2.columns\n",
    "    for i in range(0,len(column_list1)):\n",
    "        col_i = column_list1[i]\n",
    "        dtype1 = dtypes_dict1[col_i]\n",
    "        dtype2 = dtypes_dict2[col_i]\n",
    "        if(dtype1!=dtype2):\n",
    "            print(col_i,dtype1,dtype2)        \n",
    "def aligndataframes(df1,df2):\n",
    "    dtypes_dict1 = df1.dtypes.apply(lambda x: x.name).to_dict()\n",
    "    dtypes_dict2 = df2.dtypes.apply(lambda x: x.name).to_dict()\n",
    "    column_list1 = df1.columns\n",
    "    column_list2 = df2.columns\n",
    "    for i in range(0,len(column_list1)):\n",
    "        col_i = column_list1[i]\n",
    "        dtype1 = dtypes_dict1[col_i]\n",
    "        dtype2 = dtypes_dict2[col_i]\n",
    "        try:\n",
    "         if(dtype1!=dtype2):\n",
    "             if(dtype2 == 'object' and ((dtype1 == 'float64') or (dtype1 == 'int64'))):\n",
    "                df2[col_i] = df2[col_i].apply(lambda x:nan if str.strip (str(x)) =='' else x)\n",
    "                df2[col_i] = df2[col_i].astype(df1[col_i].dtype)\n",
    "             elif(((dtype2 == 'float64') or (dtype2 == 'int64')) and dtype1 == 'object'):\n",
    "                 df1[col_i] = df1[col_i].apply(lambda x:nan if str.strip (str(x)) =='' else x)\n",
    "                 df1[col_i] = df1[col_i].astype(df2[col_i].dtype)\n",
    "             elif(dtype1 =='float64' and dtype2 =='int64'):\n",
    "                 df2[col_i] = df2[col_i].astype(df1[col_i].dtype)     \n",
    "             elif(dtype1 =='int64' and dtype2 =='float64'):\n",
    "                 df1[col_i] = df1[col_i].astype(df2[col_i].dtype)             \n",
    "             else:\n",
    "                 print(dtype1,dtype2)\n",
    "        except Exception as e:\n",
    "            print(col_i,dtype1,dtype2)\n",
    "            if(dtype2 == 'object' and ((dtype1 == 'float64') or (dtype1 == 'int64'))):\n",
    "                df1[col_i] = df1[col_i].astype(df2[col_i].dtype)\n",
    "                pd.set_option('future.no_silent_downcasting', True)\n",
    "                df1[col_i] = df1[col_i].fillna('')\n",
    "            elif(((dtype2 == 'float64') or (dtype2 == 'int64')) and dtype1 == 'object'):\n",
    "                 df2[col_i] = df2[col_i].astype(df1[col_i].dtype)\n",
    "                 pd.set_option('future.no_silent_downcasting', True)\n",
    "                 df2[col_i] = df2[col_i].fillna('')\n",
    "            elif(dtype1 =='float64' and dtype2 =='int64'):\n",
    "                 df1[col_i] = df1[col_i].astype(df2[col_i].dtype)  \n",
    "            else:\n",
    "                 print(dtype1,dtype2)\n",
    "    return df1,df2\n",
    "\n",
    "def get_distinct_column_values(df, column_name):\n",
    "    return df[column_name].unique()\n",
    "\n",
    "def check_duplicates(df1,key_columns):\n",
    "    df2 = df1.drop_duplicates(key_columns)\n",
    "    print(len(df2),len(df1))\n",
    "    print('difference: ',len(df2)-len(df1))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def compare_files_from_containers(blob1,blob2,container1,container2,connect_storage_str,key_columns,value_columns,sep1, lineterminator1):\n",
    "    df1_data = get_filedata_from_container(connect_storage_str,container1,blob1)\n",
    "    df2_data = get_filedata_from_container(connect_storage_str,container2,blob2)\n",
    "    df1 = pd.read_csv(df1_data, sep=sep1, lineterminator=lineterminator1)\n",
    "    df1 = convert_column_names_to_uppercase(df1)\n",
    "    dtypes_dict = df1.dtypes.apply(lambda x: x.name).to_dict()\n",
    "    df2 = pd.read_csv(df2_data, sep=sep1, lineterminator=lineterminator1)\n",
    "    df2 = convert_column_names_to_uppercase(df2)\n",
    "    df2['CC_ENTITY'] = df2['CC_ENTITY'].fillna(' ')\n",
    "    print(\"shapes of dfs\",df1.shape,df2.shape)\n",
    "    df1,df2 = aligndataframes(df1,df2)\n",
    "    print(\"difference records \",df1.shape[0]-df2.shape[0])\n",
    "    #print(compare_column_dtypes(df1,df2))\n",
    "    #return df1,df2\n",
    "    merged_df,merged_df_results = compare_dataframes(df1, df2, key_columns, value_columns)\n",
    "    return df1,df2,merged_df,merged_df_results\n",
    "\n",
    "def get_df_before_compare_files_from_containers(blob1,blob2,container1,container2,connect_storage_str,sep1, lineterminator1):\n",
    "    df1_data = get_filedata_from_container(connect_storage_str,container1,blob1)\n",
    "    df2_data = get_filedata_from_container(connect_storage_str,container2,blob2)\n",
    "    df1 = pd.read_csv(df1_data, sep=sep1, lineterminator=lineterminator1)\n",
    "    df1 = convert_column_names_to_uppercase(df1)\n",
    "    dtypes_dict = df1.dtypes.apply(lambda x: x.name).to_dict()\n",
    "    df2 = pd.read_csv(df2_data, sep=sep1, lineterminator=lineterminator1)\n",
    "    df2 = convert_column_names_to_uppercase(df2)\n",
    "    #df2['CC_ENTITY'] = df2['CC_ENTITY'].fillna(' ')\n",
    "    print(\"shapes of dfs\",df1.shape,df2.shape)\n",
    "    try:\n",
    "       df1,df2 = aligndataframes(df1,df2)\n",
    "    except Exception as e:\n",
    "        print(\"error: \",e)\n",
    "        return df1,df2\n",
    "    print(\"difference records \",df1.shape[0]-df2.shape[0])\n",
    "    #print(compare_column_dtypes(df1,df2))\n",
    "    #return df1,df2\n",
    "    return df1,df2\n",
    "\n",
    "def get_df_before_compare_files_from_containers_dict(blob1,blob2,container1,container2,connect_storage_str,sep1, lineterminator1,columns_dict):\n",
    "    try:\n",
    "        df1_data = get_filedata_from_container(connect_storage_str,container1,blob1)\n",
    "        df2_data = get_filedata_from_container(connect_storage_str,container2,blob2)\n",
    "        df1 = pd.read_csv(df1_data, sep=sep1, lineterminator=lineterminator1, dtype=columns_dict)\n",
    "        #df1 = pd.read_csv(df1_data, sep=sep1, lineterminator=lineterminator1)\n",
    "        df1 = convert_column_names_to_uppercase(df1)\n",
    "        df2 = pd.read_csv(df2_data, sep=sep1, lineterminator=lineterminator1, dtype=columns_dict)\n",
    "        #df2 = pd.read_csv(df2_data, sep=sep1, lineterminator=lineterminator1)\n",
    "        df2 = convert_column_names_to_uppercase(df2)\n",
    "        #df2['CC_ENTITY'] = df2['CC_ENTITY'].fillna(' ')\n",
    "        print(\"shapes of dfs\",df1.shape,df2.shape) \n",
    "        #df1,df2 = aligndataframes(df1,df2)\n",
    "    except Exception as e:\n",
    "        print(\"error: \",e)\n",
    "        df1 = pd.DataFrame()\n",
    "        df2 = pd.DataFrame()\n",
    "        return df1,df2\n",
    "    print(\"difference records \",df1.shape[0]-df2.shape[0])\n",
    "    #print(compare_column_dtypes(df1,df2))\n",
    "    #return df1,df2\n",
    "    return df1,df2\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def find_unique_records_leftondf1(df1, df2, key_columns):\n",
    "    merged_df = df1.merge(df2, on=key_columns, how='left', indicator=True)\n",
    "    unique_records = merged_df[merged_df['_merge'] == 'left_only']\n",
    "    unique_records = unique_records.drop(columns=['_merge'])\n",
    "    return unique_records\n",
    "\n",
    "\n",
    "def find_unique_records_inner(df1, df2, key_columns):\n",
    "    merged_df = df1.merge(df2, on=key_columns, how='inner',suffixes =('_x','_y'))\n",
    "    #order = get_column_order(df1.columns,key_columns)\n",
    "    return merged_df#[order]\n",
    "\n",
    "def compare_dataframes2(df1, df2, key_column, value_columns):\n",
    "    value_columns = [x for x in value_columns if x not in key_columns]\n",
    "    merged_df = df1.merge(df2, on=key_column, suffixes=('_df1', '_df2'))\n",
    "    merged_df_results = merged_df\n",
    "    merged_df_keys = merged_df_results[key_columns]\n",
    "    #print(merged_df.columns)\n",
    "    #print('original count',df1.count,df2.count) #print(\"shapes of dfs\",df1.shape,df2.shape)\n",
    "    print(\"common records on given key\",merged_df.shape)\n",
    "    discrepancies = pd.DataFrame()\n",
    "    for column in value_columns:\n",
    "        merged_df_results[f'{column}_df1df2'] = merged_df_results.apply(lambda row: 1 if comparator(row[f'{column}_df1'],row[f'{column}_df2']) else 0, axis=1)\n",
    "    return merged_df,merged_df_results,merged_df_keys\n",
    "\n",
    "\n",
    "\n",
    "def re_compare_files_from_containers(df1,df2,key_columns,value_columns):\n",
    "    print(\"shapes of dfs\",df1.shape,df2.shape)\n",
    "    print(\"difference records \",df1.shape[0]-df2.shape[0])\n",
    "    merged_df,merged_df_results,merged_df_keys = compare_dataframes2(df1, df2, key_columns, value_columns)\n",
    "    return merged_df,merged_df_results#,merged_df_keys\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def get_df3(df1, df2, key_columns):\n",
    "    #merged_df = df2.merge(df1, on=key_columns, how='left', indicator=True, suffixes=('_df1', '_df2'))\n",
    "    merged_df = df2.merge(df1, on=key_columns, how='left', indicator=True, suffixes=('_df1', '_df2'))\n",
    "    df3 = merged_df[merged_df['_merge'] == 'left_only'].drop(columns=['_merge'])\n",
    "    df1_columns = df1.columns\n",
    "    ordered_columns = key_columns + [col + suffix for col in df1.columns if col not in key_columns for suffix in ['_df1', '_df2']]\n",
    "    df3 = df3[ordered_columns]\n",
    "    return df3\n",
    "\n",
    "def record_level_difference(key_columns, df1,df2):\n",
    "    print(\"shapes of dfs\",df1.shape,df2.shape)\n",
    "    df1 = convert_column_names_to_uppercase(df1)\n",
    "    df2 = convert_column_names_to_uppercase(df2)\n",
    "    count1 = df1.shape[0]\n",
    "    count2 = df2.shape[0]\n",
    "    print('counts are:',count1,count2)\n",
    "    print('coutn difference :', (count1-count2 if count1-count2>0 else count2-count1))\n",
    "    if(count1>count2):\n",
    "       print('df1 is bigger')\n",
    "       #df3 = get_df3(df2, df1, key_columns)\n",
    "    else:\n",
    "        print('df2 is bigger')\n",
    "        #df3 = get_df3(df1, df2, key_columns)\n",
    "    df3 = get_df3(df1, df2, key_columns)\n",
    "    df4 = get_df3(df2, df1, key_columns)\n",
    "    print (df3.shape)\n",
    "    print (df4.shape)\n",
    "    return df3,df4\n",
    "\n",
    "\n",
    "#key_columns = ['CLAIM_NUMBER','SERVICE_LINE']\n",
    "#value_columns = ['SOURCE_SYSTEM','CC_entity','CLAIM_NUMBER','SERVICE_LINE','REVENUE_CODE','CLAIM_STATUS','FACILITY_TYPE_CODE','PROCEDURE_CODE','MODIFIER_1','MODIFIER_2','MODIFIER_3','Modifier_4','Emergency_Flag','NDC_Code','Hospital_Related_Flag','Outside_Labs_Flag','PAID_AMOUNT','Billed_Amount','Value_Amount','UNIT_COUNT','SERVICE_FROM_DATE','SERVICE_TO_DATE','COPAY_AMOUNT','DEDUCTIBLE_AMOUNT','COINSURANCE_AMOUNT','PATIENT_LIABILITY_AMOUNT','Adjustment_Code','Adjustment_Desc','Discount_Type_Code','DISCOUNT_AMOUNT','Adjudication_Date','Benefit_Limit_Amount','Admitting_Provider_ID','Business_Unit_Number','COVERED_AMOUNT','Earliest_Service_From_Date','Eligible_Amount','Last_Service_Date','National_Drug_Code','Net_Paid_Amount','NPI_TAXONOMY_CODE','Original_Place_of_Service_Code','Servicing_NPI_Taxonomy_Code','Subscriber_Number']\n",
    "def to_uppercase_comprehension(strings):\n",
    "    return [string.upper() for string in strings]\n",
    "#key_columns = to_uppercase_comprehension(key_columns)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#to be used post compare_dataframes\n",
    "def sort_objects_by_values(objects, values):\n",
    "    paired_list = list(zip(objects, values))\n",
    "    sorted_paired_list = sorted(paired_list, key=lambda x: x[1], reverse=False)\n",
    "    sorted_objects = [item[0] for item in sorted_paired_list]\n",
    "    return sorted_objects\n",
    "\n",
    "\n",
    "def get_difference_records(md,value_columns,key_columns):\n",
    "    value_columns = [x for x in value_columns if x not in key_columns]\n",
    "    condition = False\n",
    "    for i in range(0,len(value_columns)):\n",
    "        condition = condition | (md[f'{value_columns[i]}_df1df2'] == 0)\n",
    "    md = md[condition]\n",
    "    df1df2_columns = []\n",
    "    df1df2_columns_counts = []\n",
    "    for  i in range(0,len(value_columns)):\n",
    "        count = md[f'{value_columns[i]}_df1df2'].sum()\n",
    "        df1df2_columns_counts.append(count)\n",
    "    sorted_value_columns = sort_objects_by_values(value_columns,df1df2_columns_counts)\n",
    "    final_column_list = key_columns\n",
    "    for i in range(0,len(sorted_value_columns)):\n",
    "        final_column_list.append(f'{sorted_value_columns[i]}_df1')\n",
    "        final_column_list.append(f'{sorted_value_columns[i]}_df2')\n",
    "        final_column_list.append(f'{sorted_value_columns[i]}_df1df2')\n",
    "    md = md[final_column_list]\n",
    "    return md\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "validation",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
